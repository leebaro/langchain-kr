{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec680f5",
   "metadata": {},
   "source": [
    "# LangGraph 활용 Agent 구축\n",
    "\n",
    "이번 튜토리얼에서는 웹 검색 도구를 통해 챗봇에 웹 검색 기능수행하는 Agent 을 추가합니다.\n",
    "\n",
    "LLM 에 도구를 바인딩하여 LLM 에 입력된 요청에 따라 필요시 웹 검색 도구(Tool)를 호출하는 Agent 을 구축합니다.\n",
    "\n",
    "뿐만아니라, 조건부 엣지를 통해 도구 호출 여부에 따라 다른 노드로 라우팅하는 방법도 함께 배워봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9d9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5c6228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Modules\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5376bf",
   "metadata": {},
   "source": [
    "## 도구(Tool) 사용하기\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [도구(Tools)](https://wikidocs.net/262582)\n",
    "\n",
    "챗봇이 \"기억\"에서 답변할 수 없는 질문을 처리하기 위해 웹 검색 도구를 통합할 것입니다. 이 도구를 사용하여 관련 정보를 찾아 더 나은 응답을 제공할 수 있습니다.\n",
    "\n",
    "### 검색 API 도구\n",
    "\n",
    "Tavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: `TavilySearchResults`와 `TavilyAnswer`.\n",
    "\n",
    "**API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "발급한 API 키를 환경변수에 설정합니다.\n",
    "\n",
    "`.env` 파일에 아래와 같이 설정합니다.\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**설명**\n",
    "- Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\n",
    "- 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\n",
    "- 현재 이벤트에 대한 질문에 답변할 때 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbcea8",
   "metadata": {},
   "source": [
    "다음으로 웹 검색 도구인 `TavilySearchResults`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163da255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04fccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다. ada-code-search-text code-search-ada-text-001 result = llm_chain.apply(input_list) generated_result = llm_chain.generate(input_list) generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))] [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] result = llm_chain.apply(input_list) 태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\", 'score': 0.80070794, 'raw_content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n2023년 09월 28일 5 분 소요\\n목차\\n\\n🌱 랭체인의 주요 기능\\n🌱 환경설정\\nAPI KEY 발급\\n모듈 설치(openai, langchain)\\n\\n\\n🔥 ChatOpenAI\\n🔥 프롬프트 템플릿의 활용\\nLLMChain 객체\\n① run()\\n② apply()\\n③ generate()\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n⑤ 스트리밍(streaming)\\n\\n\\n\\n언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다.\\n튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다.\\n🌱 랭체인의 주요 기능\\n랭체인을 통해 다음과 같은 특징을 갖는 애플리케이션을 개발할 수 있습니다.\\n\\n문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\\n추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\\n\\n랭체인의 가치\\n랭체인의 핵심적인 가치는 여러 가지가 있지만, 그 중에서도 두 가지 주요한 점을 꼽자면 다음과 같습니다.\\n\\n구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\\n사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다.\\n\\n특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.\\n🌱 환경설정\\nAPI KEY 발급\\n먼저, openai 의 API KEY 를 발급 받아야 합니다. 발급은 다음의 절차를 통해 진행할 수 있습니다.\\nhttps://platform.openai.com/account/api-keys 로 접속합니다.\\n\\nLog in 버튼을 클릭 후 계정에 로그인 합니다. 계정이 아직 생성되지 않은 경우에는 Sign up 으로 회원가입 후 로그인 합니다.\\n\\n\\n\\n“Create new secret key” 버튼을 클릭하여 새로운 키를 발급합니다.\\n\\n\\n\\nName 에는 발급하는 키에 대한 별칭을 입력합니다.\\n\\n\\n\\n새롭게 발급한 키를 복사합니다. 잃어버리면 다시 발급하여야 하므로, 안전한 곳에 저장해 둡니다.\\n\\n\\n모듈 설치(openai, langchain)\\npip 명령어로 모듈을 설치 합니다. 아나콘다 가상환경에서 설치해도 좋습니다.\\n```\\nopenai 파이썬 패키지 설치\\npip install openai langchain\\n```\\n먼저, 설치한 openai 모듈을 import 한 뒤, 발급받은 API KEY를 다음과 같이 설정합니다.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY 입력'\\n```\\n사용 가능한 모델 리스트 출력\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\n🔥 ChatOpenAI\\nOpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\\n객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\\ntemperature\\n\\n사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\\n\\nmax_tokens\\n\\n채팅 완성에서 생성할 토큰의 최대 개수입니다.\\n\\nmodel_name: 적용 가능한 모델 리스트\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                )\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n질의\\nprint(f'[답변]: {llm.predict(question)}')\\n```\\n[답변]: 대한민국의 수도는 서울입니다.\\n🔥 프롬프트 템플릿의 활용\\nPromptTemplate\\n\\n\\n사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\\n\\n\\n사용법\\n\\n\\ntemplate: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\\n\\n\\ninput_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\\n\\n\\n사용법: 리스트 형식으로 변수 이름을 정의합니다.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\n질문 템플릿 형식 정의\\ntemplate = '{country}의 수도는 뭐야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain 객체\\nLLMChain\\n\\n\\nLLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\\n\\n\\n사용법\\n\\n\\nprompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\\n\\n\\nllm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\\n\\n\\n\\n\\n```\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n① run()\\nrun() 함수로 템플릿 프롬프트 실행\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='일본'))\\n```\\n일본의 수도는 도쿄입니다.\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='캐나다'))\\n```\\n캐나다의 수도는 오타와(Ottawa)입니다.\\n② apply()\\napply() 함수로 여러개의 입력을 한 번에 실행\\n```\\ninput_list = [\\n    {'country': '호주'},\\n    {'country': '중국'},\\n    {'country': '네덜란드'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': '호주의 수도는 캔버라입니다.'},\\n {'text': '중국의 수도는 베이징(北京)입니다.'},\\n {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]\\ntext 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\\n이를 반복문으로 출력한다면 다음과 같습니다.\\n```\\ninput_list 에 대한 결과 반환\\nresult = llm_chain.apply(input_list)\\n반복문으로 결과 출력\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n③ generate()\\ngenerate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\\nLLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\\n```\\ninput_list 에 대한 결과 반환\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]\\n```\\n토큰 사용량 출력\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID 출력\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\\n이번에는 2개 이상의 변수(input_variables) 를 활용하여 템플릿 구성을 해보겠습니다.\\n```\\n질문 템플릿 형식 정의\\ntemplate = '{area1} 와 {area2} 의 시차는 몇시간이야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\n체인 실행: run()\\nprint(llm_chain.run(area1='서울', area2='파리'))\\n```\\n서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\\n```\\ninput_list = [\\n    {'area1': '파리', 'area2': '뉴욕'},\\n    {'area1': '서울', 'area2': '하와이'},\\n    {'area1': '켄버라', 'area2': '베이징'}\\n]\\n반복문으로 결과 출력\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n파리와 뉴욕의 시차는 일반적으로 6시간입니다. 파리가 뉴욕보다 6시간 앞서 있습니다. 예를 들어, 파리가 오전 9시라면 뉴욕은 오전 3시입니다.\\n서울과 하와이의 시차는 서울이 하와이보다 19시간 빠릅니다. 예를 들어, 서울이 오전 9시라면 하와이는 전날 오후 2시입니다.\\n켄버라와 베이징의 시차는 2시간입니다. 켄버라는 오스트레일리아의 수도로 UTC+10 시간대에 위치하고, 베이징은 중국의 수도로 UTC+8 시간대에 위치합니다.\\n⑤ 스트리밍(streaming)\\n스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\\n다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n스트리밍으로 답변 출력\\nresponse = llm.predict(question)\\n```\\n대한민국의 수도는 서울입니다.\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\\n카테고리: langchain\\n업데이트: 2023년 09월 28일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {'title': '랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-04/', 'content': '랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4) - 테디노트 랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4) 랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4) 이번 포스팅에서는 랭체인(LangChain) 을 활용하여 정형데이터(CSV, Excel) 에 대한 ChatGPT 기반 질의응답을 통해 데이터 분석하는 방법 에 대해 알아보겠습니다. 이번 튜토리얼에서는 langchain 의 create_pandas_dataframe_agent() 을 통해 에이전트를 생성한 뒤, 생성된 에이전트에 자연어로 데이터에 대한 질의 응답 을 통해 원하는 분석 결과를 도출하는 방법에 대해 다루겠습니다. 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 from langchain.agents import create_pandas_dataframe_agent Thought:The difference in average age between df1 and df2 is approximately 5.9. Thought:The percentage difference in average age between df1 and df2 is approximately 19.87%. 태그: ChatGPT, ChatOpenAI, csv, excel, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 데이터분석, 랭체인, 랭체인 튜토리얼', 'score': 0.77589405, 'raw_content': '랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석 (4)\\n2023년 10월 02일 4 분 소요\\n목차\\n\\n🌱 환경설정\\n🔥 데이터 로드\\n🔥 Pandas DataFrame Agent\\n🔥 2개 이상의 DataFrame\\n\\n이번 포스팅에서는 랭체인(LangChain) 을 활용하여 정형데이터(CSV, Excel) 에 대한 ChatGPT 기반 질의응답을 통해 데이터 분석하는 방법 에 대해 알아보겠습니다.\\n이번 튜토리얼에서는 langchain 의 create_pandas_dataframe_agent() 을 통해 에이전트를 생성한 뒤, 생성된 에이전트에 자연어로 데이터에 대한 질의 응답 을 통해 원하는 분석 결과를 도출하는 방법에 대해 다루겠습니다.\\n한가지 흥미로운 사실은 자연어로 에이전트에 질문하면, 에이전트가 이를 pandas 문법을 변환하여 코드를 실행한 뒤, 결과를 다시 자연어로 반환해 준다는 점입니다. 에이전트가 답변을 도출하는 과정에서 실행한 pandas 코드도 확인 할 수 있습니다.\\n\\n✔️ (이전글) LangChain 튜토리얼\\n\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법\\n랭체인(langchain) + 허깅페이스(HuggingFace) 모델 사용법\\n랭체인(langchain) + 챗(chat) - ConversationChain, 템플릿 사용법\\n\\n\\n🌱 환경설정\\n\\n라이브러리 설치\\n\\n```\\n필요한 라이브러리 설치\\npip install langchain openai\\n```\\nOPENAI API KEY 를 설정합니다.\\n```\\nOPENAI_API\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'OPENAI API KEY 입력\\'\\n```\\n🔥 데이터 로드\\npandas를 활용하여 csv 파일을 DataFrame 으로 로드합니다.\\n```\\nimport pandas as pd\\ncsv 파일을 데이터프레임으로 로드\\ndf = pd.read_csv(\\'data/titanic.csv\\')\\ndf.head()\\n```\\n|  | survived | pclass | sex | age | sibsp | parch | fare | embarked | class | who | adult_male | deck | embark_town | alive | alone |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 0 | 3 | male | 22.0 | 1 | 0 | 7.2500 | S | Third | man | True | NaN | Southampton | no | False |\\n| 1 | 1 | 1 | female | 38.0 | 1 | 0 | 71.2833 | C | First | woman | False | C | Cherbourg | yes | False |\\n| 2 | 1 | 3 | female | 26.0 | 0 | 0 | 7.9250 | S | Third | woman | False | NaN | Southampton | yes | True |\\n| 3 | 1 | 1 | female | 35.0 | 1 | 0 | 53.1000 | S | First | woman | False | C | Southampton | yes | False |\\n| 4 | 0 | 3 | male | 35.0 | 0 | 0 | 8.0500 | S | Third | man | True | NaN | Southampton | no | True |\\n🔥 Pandas DataFrame Agent\\n```\\nfrom langchain.agents import create_pandas_dataframe_agent\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.agents.agent_types import AgentType\\n에이전트 생성\\nagent = create_pandas_dataframe_agent(\\n    ChatOpenAI(temperature=0, \\n               model=\\'gpt-4-0613\\'),        # 모델 정의\\n    df,                                    # 데이터프레임\\n    verbose=True,                          # 추론과정 출력\\n    agent_type=AgentType.OPENAI_FUNCTIONS, # AgentType.ZERO_SHOT_REACT_DESCRIPTION\\n)\\n```\\n```\\n질의\\nagent.run(\\'데이터의 행과 열의 갯수는 어떻게 돼?\\')\\n```\\nEntering new AgentExecutor chain...\\nInvoking: `python_repl_ast` with `{\\'query\\': \\'df.shape\\'}`\\n(891, 15)데이터프레임 `df`는 891개의 행과 15개의 열로 구성되어 있습니다.\\nFinished chain.\\n\\'데이터프레임 `df`는 891개의 행과 15개의 열로 구성되어 있습니다.\\'\\n```\\n질의\\nagent.run(\\'남자 승객의 생존율을 어떻게 돼? %로 알려줘\\')\\n```\\nEntering new AgentExecutor chain...Thought: To find the survival rate of male passengers, I need to filter the dataframe for rows where \\'sex\\' is \\'male\\', then calculate the mean of the \\'survived\\' column. This will give the proportion of male passengers who survived, which I can then multiply by 100 to get a percentage.\\nAction: python_repl_ast\\nAction Input: male_survival_rate = df[df[\\'sex\\'] == \\'male\\'][\\'survived\\'].mean() * 100\\nObservation: \\nThought:Now I need to print the survival rate to see the result.\\nAction: python_repl_ast\\nAction Input: print(male_survival_rate)\\nObservation: 18.890814558058924\\nThought:I now know the final answer\\nFinal Answer: 남자 승객의 생존율은 약 18.89%입니다.\\nFinished chain.\\n\\'남자 승객의 생존율은 약 18.89%입니다.\\'\\n```\\n질의\\nagent.run(\\'나이가 15세 이하인 승객중 1,2등급에 탑승한 남자 승객의 생존율은 어떻게 돼? %로 알려줘\\')\\n```\\nEntering new AgentExecutor chain...\\nInvoking: `python_repl_ast` with `{\\'query\\': \"df_child_male = df[(df[\\'age\\'] <\\\\= 15) & (df[\\'sex\\'] == \\'male\\') & (df[\\'pclass\\'].isin([1, 2]))]\\\\nchild_male_survival_rate = df_child_male[\\'survived\\'].mean() * 100\\\\nchild_male_survival_rate\"}`\\n100.0나이가 15세 이하인 승객 중 1,2등급에 탑승한 남자 승객의 생존율은 100%입니다.\\nFinished chain.\\n\\'나이가 15세 이하인 승객 중 1,2등급에 탑승한 남자 승객의 생존율은 100%입니다.\\'\\n🔥 2개 이상의 DataFrame\\n2개 이상의 데이터프레임에 기반한 LLM 기반 질의를 할 수 있습니다. 2개 이상의 데이터프레임 입력시 [] 로 묶어주면 됩니다.\\n```\\n샘플 데이터프레임 생성\\ndf1 = df.copy()\\ndf1 = df1.fillna(0)\\ndf1.head()\\n```\\n|  | survived | pclass | sex | age | sibsp | parch | fare | embarked | class | who | adult_male | deck | embark_town | alive | alone |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| 0 | 0 | 3 | male | 22.0 | 1 | 0 | 7.2500 | S | Third | man | True | 0 | Southampton | no | False |\\n| 1 | 1 | 1 | female | 38.0 | 1 | 0 | 71.2833 | C | First | woman | False | C | Cherbourg | yes | False |\\n| 2 | 1 | 3 | female | 26.0 | 0 | 0 | 7.9250 | S | Third | woman | False | 0 | Southampton | yes | True |\\n| 3 | 1 | 1 | female | 35.0 | 1 | 0 | 53.1000 | S | First | woman | False | C | Southampton | yes | False |\\n| 4 | 0 | 3 | male | 35.0 | 0 | 0 | 8.0500 | S | Third | man | True | 0 | Southampton | no | True |\\n```\\n에이전트 생성\\nagent = create_pandas_dataframe_agent(\\n    ChatOpenAI(temperature=0, \\n               model=\\'gpt-4-0613\\'),\\n               [df, df1], \\n               verbose=True\\n)\\n질의\\nagent.run(\\'나이 컬럼의 나이의 평균차이는 어떻게 돼? %로 구해줘.\\')\\n```\\nEntering new AgentExecutor chain...Thought: To find the average age difference between the two dataframes, I need to calculate the average age in each dataframe and then find the difference. I will then convert this difference to a percentage.\\nAction: python_repl_ast\\nAction Input: df1[\\'age\\'].mean()\\nObservation: 29.69911764705882\\nThought:The average age in df1 is approximately 29.7. Now I will calculate the average age in df2.\\nAction: python_repl_ast\\nAction Input: df2[\\'age\\'].mean()\\nObservation: 23.79929292929293\\nThought:The average age in df2 is approximately 23.8. Now I will calculate the difference between the two averages.\\nAction: python_repl_ast\\nAction Input: abs(df1[\\'age\\'].mean() - df2[\\'age\\'].mean())\\nObservation: 5.899824717765892\\nThought:The difference in average age between df1 and df2 is approximately 5.9. Now I will convert this difference to a percentage of the average age in df1.\\nAction: python_repl_ast\\nAction Input: (abs(df1[\\'age\\'].mean() - df2[\\'age\\'].mean()) / df1[\\'age\\'].mean()) * 100\\nObservation: 19.865319865319858\\nThought:The percentage difference in average age between df1 and df2 is approximately 19.87%.\\nFinal Answer: The average age difference between the two dataframes is approximately 19.87%.\\nFinished chain.\\n\\'The average age difference between the two dataframes is approximately 19.87%.\\'\\n태그: ChatGPT, ChatOpenAI, csv, excel, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 데이터분석, 랭체인, 랭체인 튜토리얼\\n카테고리: langchain\\n업데이트: 2023년 10월 02일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.'}, {'title': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-08/', 'content': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트 Langchain  랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) ④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌 랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) 이번 포스팅에서는 랭체인(LangChain) 을 활용하여 PDF 문서를 로드하고, 문서의 내용에 기반하여 질의응답(Question-Answering) 하는 방법에 대해 알아보겠습니다. 이번 튜토리얼에서는 langchain 의 문서 로드 - 분할 - 벡터스토어(vectorstore)에 임베딩된 문서를 저장 하는 방법을 다룹니다. 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 랭체인(langchain) + PDF 문서요약, Map-Reduce from langchain.document_loaders import PyPDFLoader from langchain.text_splitter import CharacterTextSplitter from langchain.embeddings.openai import OpenAIEmbeddings from langchain.vectorstores import Chroma 아래의 예제는 langchain hub 에서 RAG Prompt 를 가져오는 예제입니다. from langchain import hub from langchain.chat_models import ChatOpenAI 태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, 랭체인, 랭체인 튜토리얼, 문서요약, 질의응답, 크롤링 카테고리: langchain', 'score': 0.7578844, 'raw_content': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8)\\n2023년 10월 13일 2 분 소요\\n목차\\n\\n🌱 환경설정\\n🔥 PDF 기반 질의 응답(Question-Answering)\\n① 데이터 로드\\n② 데이터 분할\\n③ 저장 및 검색\\n④ 프롬프트 템플릿\\n⑤ 생성\\n⑥ 테스트\\n\\n\\n\\n이번 포스팅에서는 랭체인(LangChain) 을 활용하여 PDF 문서를 로드하고, 문서의 내용에 기반하여 질의응답(Question-Answering) 하는 방법에 대해 알아보겠습니다.\\n이번 튜토리얼에서는 langchain 의 문서 로드 - 분할 - 벡터스토어(vectorstore)에 임베딩된 문서를 저장 하는 방법을 다룹니다. 여러 벡터스토어 중 오픈소스인 Chroma DB 를 활용합니다.\\n후반부에는 langchain hub 에서 프롬프트를 다운로드 받고, 이를 ChatGPT 모델과 결합하여 문서에 기반한 질의응답 Chain 을 생성합니다.\\n\\n✔️ (이전글) LangChain 튜토리얼\\n\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법\\n랭체인(langchain) + 허깅페이스(HuggingFace) 모델 사용법\\n랭체인(langchain) + 챗(chat) - ConversationChain, 템플릿 사용법\\n랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n랭체인(langchain) + 웹사이트 크롤링 - 웹사이트 문서 요약\\n랭체인(langchain) + 웹사이트 정보 추출 - 스키마 활용법\\n랭체인(langchain) + PDF 문서요약, Map-Reduce\\n\\n\\n🌱 환경설정\\n```\\n필요한 라이브러리 설치\\n!pip install -q openai langchain langchainhub pypdf\\n```\\n```\\nOPENAI_API\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'OPENAI API KEY 입력\\'\\n```\\n```\\n토큰 정보로드를 위한 라이브러리\\n설치: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n토큰 정보로드\\nload_dotenv()\\n```\\nTrue\\n🔥 PDF 기반 질의 응답(Question-Answering)\\n\\n다음은 비구조화된 데이터를 QA 체인(Question-Answering chain) 으로 변환하는 파이프라인에 대한 기술적 번역입니다:\\n\\n\\n데이터 로드: 우선, 데이터를 로드해야 합니다. LangChain 통합 허브를 사용하여 전체 로더 세트를 둘러보세요.\\n\\n\\n데이터 분할: 텍스트 분할기는 문서를 지정된 크기의 분할로 나눕니다.\\n\\n\\n저장: 저장소(예: 종종 vectorstore)는 분할을 보관하고 종종 임베드합니다.\\n\\n\\n검색: 앱은 저장소에서 분할을 검색합니다(예: 종종 입력 질문과 유사한 임베딩으로).\\n\\n\\n생성: LLM은 질문과 검색된 데이터를 포함하는 프롬프트를 사용하여 답변을 생성합니다.\\n\\n\\n① 데이터 로드\\nPyPDFLoader 를 활용하여 PDF 파일을 로드 합니다.\\n```\\nfrom langchain.document_loaders import PyPDFLoader\\nPDF 파일 로드\\nloader = PyPDFLoader(\"data/황순원-소나기.pdf\")\\ndocument = loader.load()\\ndocument[0].page_content[:200] # 내용 추출\\n```\\n\\'- 1 -소나기\\\\n황순원\\\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\\\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\\\n못하기나 한 듯이.\\\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\\\n서 하더니 , 오늘은 징검다리 한가운\\'\\n② 데이터 분할\\nCharacterTextSplitter 로 chunk_size 기준으로 문서를 쪼갭니다. chunk_overlap 에 50개의 토큰을 지정하여 문서-문서 간 겹쳐지는 부분(overlap) 이 있도록 하여 비교적 유연한 요약 결과를 도출할 수 있도록 합니다.\\n```\\nfrom langchain.text_splitter import CharacterTextSplitter\\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\\ntexts = text_splitter.split_documents(document)\\n```\\n③ 저장 및 검색\\nOpenAIEmbeddings 를 활용하여 문서의 내용을 임베딩한 뒤, Chroma 벡터스토어(vectorstore) 에 저장합니다.\\n마지막 줄에는 as_retriever() 로 retriever 형태로 가져오는데, 이는 추후 사용자의 query 입력시, 입력된 query로 vectorestore에서 유사성이 높은 데이터를 추출해 낼 때 쓰입니다.\\n```\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\n임베딩\\nembeddings = OpenAIEmbeddings()\\nChroma DB 에 저장\\ndocsearch = Chroma.from_documents(texts, embeddings)\\nretriever 가져옴\\nretriever = docsearch.as_retriever()\\n```\\n④ 프롬프트 템플릿\\n아래의 예제는 langchain hub 에서 RAG Prompt 를 가져오는 예제입니다.\\n이처럼 langchain hub 에서 공개된 프롬프트를 다운로드 받거나, ChatPromptTemplate 를 직접 생성하는 것도 가능합니다. 자세한 사항은 ConversationChain, 템플릿 사용법 에서 확인할 수 있습니다.\\n```\\nlangchain hub 에서 Prompt 다운로드 예시\\nhttps://smith.langchain.com/hub/rlm/rag-prompt\\nfrom langchain import hub\\nrag_prompt = hub.pull(\"rlm/rag-prompt\")\\nrag_prompt\\n```\\nChatPromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\\\nQuestion: {question} \\\\nContext: {context} \\\\nAnswer:\", template_format=\\'f-string\\', validate_template=True), additional_kwargs={})])\\n⑤ 생성\\n마지막 단계는 LLM 모델을 정의하고 Chain 을 생성하는 단계 입니다.\\n```\\nLLM\\nfrom langchain.chat_models import ChatOpenAI\\nChatGPT 모델 지정\\nllm = ChatOpenAI(model_name=\"gpt-4-0613\", temperature=0)\\n```\\n```\\nRAG chain 생성\\nfrom langchain.schema.runnable import RunnablePassthrough\\npipe operator를 활용한 체인 생성\\nrag_chain = (\\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \\n    | rag_prompt \\n    | llm \\n)\\n```\\n⑥ 테스트\\nrag_chain.invoke(\"이 소설의 제목은 뭐야?\")\\nAIMessage(content=\\'이 소설의 제목은 \"소나기\"입니다.\\', additional_kwargs={}, example=False)\\nrag_chain.invoke(\"이 소설의 저자는 누구야?\")\\nAIMessage(content=\\'이 소설의 저자는 황순원입니다.\\', additional_kwargs={}, example=False)\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, 랭체인, 랭체인 튜토리얼, 문서요약, 질의응답, 크롤링\\n카테고리: langchain\\n업데이트: 2023년 10월 13일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 검색 도구 생성\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록에 추가\n",
    "tools = [tool]\n",
    "\n",
    "# 도구 실행\n",
    "print(tool.invoke(\"테디노트 랭체인 튜토리얼\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b6ca3",
   "metadata": {},
   "source": [
    "결과는 챗봇이 질문에 답할 수 있도록 사용할 수 있는 페이지 요약입니다.\n",
    "\n",
    "이번에는 LLM에 `bind_tools`를 추가하여 **LLM + 도구** 를 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6166da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의\n",
    "class State(TypedDict):\n",
    "    # list 타입에 add_messages 적용(list 에 message 추가)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9e3c7",
   "metadata": {},
   "source": [
    "LLM 을 정의하고 도구를 바인딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c65ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# LLM 초기화\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "\n",
    "# LLM 에 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c2841",
   "metadata": {},
   "source": [
    "노드를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028d36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 함수 정의\n",
    "def chatbot(state: State):\n",
    "    answer = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 메시지 목록 반환\n",
    "    return {\"messages\": [answer]}  # 자동으로 add_messages 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c798e0",
   "metadata": {},
   "source": [
    "그래프 생성 및 노드를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8d16a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11975b2d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034ee74",
   "metadata": {},
   "source": [
    "## 도구 노드(Tool Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b08e3f",
   "metadata": {},
   "source": [
    "다음으로, 도구가 호출될 경우 실제로 실행할 수 있는 함수를 만들어야 합니다. 이를 위해 새로운 노드에 도구를 추가합니다.\n",
    "\n",
    "가장 최근의 메시지를 확인하고 메시지에 `tool_calls`가 포함되어 있으면 도구를 호출하는 `BasicToolNode`를 구현합니다. \n",
    "\n",
    "지금은 직접 구현하지만, 나중에는 LangGraph의 pre-built 되어있는 [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode) 로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1437765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11975b2d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Run tools requested in the last AIMessage node\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # 도구 리스트\n",
    "        self.tools_list = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # 메시지가 존재할 경우 가장 최근 메시지 1개 추출\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # 도구 호출 결과\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 도구 호출 후 결과 저장\n",
    "            tool_result = self.tools_list[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            outputs.append(\n",
    "                # 도구 호출 결과를 메시지로 저장\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(\n",
    "                        tool_result, ensure_ascii=False\n",
    "                    ),  # 도구 호출 결과를 문자열로 변환\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# 도구 노드 생성\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# 그래프에 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ecda",
   "metadata": {},
   "source": [
    "## 조건부 엣지(Conditional Edge)\n",
    "\n",
    "도구 노드가 추가되면 `conditional_edges`를 정의할 수 있습니다.\n",
    "\n",
    "**Edges**는 한 노드에서 다음 노드로 제어 흐름을 라우팅합니다. \n",
    "\n",
    "**Conditional edges**는 일반적으로 \"if\" 문을 포함하여 현재 그래프 상태에 따라 다른 노드로 라우팅합니다. 이러한 함수는 현재 그래프 `state`를 받아 다음에 호출할 Node 를 나타내는 **문자열 또는 문자열 목록** 을 반환합니다.\n",
    "\n",
    "아래에서는 `route_tools`라는 라우터 함수를 정의하여 챗봇의 출력에서 `tool_calls`를 확인합니다. \n",
    "\n",
    "이 함수를 `add_conditional_edges`를 호출하여 그래프에 제공하면, `chatbot` 노드가 완료될 때마다 이 함수를 확인하여 다음으로 어디로 갈지 결정합니다.\n",
    "\n",
    "조건은 도구 호출이 있으면 `tools`로, 없으면 `END`로 라우팅됩니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- langgraph 에 pre-built 되어 있는 [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) 으로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758bf4f",
   "metadata": {},
   "source": [
    "### `add_conditional_edges`\n",
    "\n",
    "![add_conditional_edges](./image/langgraph-02.png)\n",
    "\n",
    "`add_conditional_edges` 메서드는 시작 노드에서 여러 대상 노드로의 조건부 엣지를 추가합니다.\n",
    "\n",
    "**매개변수**\n",
    "- `source` (str): 시작 노드. 이 노드를 나갈 때 조건부 엣지가 실행됩니다.\n",
    "- `path` (Union[Callable, Runnable]): 다음 노드를 결정하는 호출 가능한 객체 또는 Runnable. `path_map`을 지정하지 않으면 하나 이상의 노드를 반환해야 합니다. `END`를 반환하면 그래프 실행이 중지됩니다.\n",
    "- `path_map` (Optional[Union[dict[Hashable, str], list[str]]]): 경로와 노드 이름 간의 매핑. 생략하면 `path`가 반환하는 값이 노드 이름이어야 합니다.\n",
    "- `then` (Optional[str]): `path`로 선택된 노드 실행 후 실행할 노드의 이름.\n",
    "\n",
    "**반환값**\n",
    "- Self: 메서드 체이닝을 위해 자기 자신을 반환합니다.\n",
    "\n",
    "**주요 기능**\n",
    "1. 조건부 엣지를 그래프에 추가합니다.\n",
    "2. `path_map`을 딕셔너리로 변환합니다.\n",
    "3. `path` 함수의 반환 타입을 분석하여 자동으로 `path_map`을 생성할 수 있습니다.\n",
    "4. 조건부 분기를 그래프에 저장합니다.\n",
    "\n",
    "**참고**\n",
    "- 이미 컴파일된 그래프에 엣지를 추가하면 경고 메시지가 출력됩니다.\n",
    "- `path` 함수의 반환 값에 대한 타입 힌트가 없거나 `path_map`이 제공되지 않으면, 그래프 시각화 시 해당 엣지가 그래프의 모든 노드로 전환될 수 있다고 가정합니다.\n",
    "- 동일한 이름의 분기가 이미 존재하는 경우 `ValueError`가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a964c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        # 가장 최근 AI 메시지 추출\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        # 입력 상태에 메시지가 없는 경우 예외 발생\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # AI 메시지에 도구 호출이 있는 경우 \"tools\" 반환\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # 도구 호출이 있는 경우 \"tools\" 반환\n",
    "        return \"tools\"\n",
    "    # 도구 호출이 없는 경우 \"END\" 반환\n",
    "    return END\n",
    "\n",
    "\n",
    "# `tools_condition` 함수는 챗봇이 도구 사용을 요청하면 \"tools\"를 반환하고, 직접 응답이 가능한 경우 \"END\"를 반환\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    # route_tools 의 반환값이 \"tools\" 인 경우 \"tools\" 노드로, 그렇지 않으면 END 노드로 라우팅\n",
    "    path_map={\"tools\": \"tools\", END: END},\n",
    ")\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab199c",
   "metadata": {},
   "source": [
    "**조건부 엣지**가 단일 노드에서 시작해야 합니다.\n",
    "\n",
    "이는 그래프에 \"`chatbot`\" 노드가 실행될 때마다 도구를 호출하면 'tools'로 이동하고, 직접 응답하면 루프를 종료하라는 의미입니다. \n",
    "\n",
    "사전 구축된 `tools_condition`처럼, 함수는 도구 호출이 없을 경우 `END` 문자열을 반환(그래프 종료) 합니다. 그래프가 `END`로 전환되면 더 이상 완료할 작업이 없으며 실행을 중지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4d1118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736b473",
   "metadata": {},
   "source": [
    "이제 봇에게 훈련 데이터 외의 질문을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31343b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='테디노트 YouTube 채널에 대해서 검색해 줘' additional_kwargs={} response_metadata={} id='96c91979-a7d2-483b-a0e8-442dbd84e238'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='' additional_kwargs={'function_call': {'name': 'tavily_web_search', 'arguments': '{\"query\": \"\\\\ud14c\\\\ub514\\\\ub178\\\\ud2b8 YouTube \\\\ucc44\\\\ub110\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-c71389eb-9538-48d2-abd7-f75315ef1b5c-0' tool_calls=[{'name': 'tavily_web_search', 'args': {'query': '테디노트 YouTube 채널'}, 'id': '52ee7bde-351d-4a8a-a5f6-7bdc8d68b92e', 'type': 'tool_call'}] usage_metadata={'input_tokens': 73, 'output_tokens': 14, 'total_tokens': 87, 'input_token_details': {'cache_read': 0}}\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='[{\"title\": \"어시웍스 - 생성형ai부터 에이전틱ai까지 비개발자도 뚝딱 [테디노트 유튜브 채널]\", \"url\": \"https://aifactory.space/forum/discussion/4186\", \"content\": \"어시웍스 - 생성형AI부터 에이전틱AI까지 비개발자도 뚝딱 [테디노트 유튜브 채널] 어시웍스 - 생성형AI부터 에이전틱AI까지 비개발자도 뚝딱 [테디노트 유튜브 채널] AF 김태영 접속하기 >> https://www.youtube.com/live/7m5Xzfd95hw Function : 텍스트 생성(LLM)이나 API 호출을 하나의 작업 단위 생성 Flow : 여러 Function, 혹은 사용자 입력을 연결하여 복잡한 로직 생성 Agent : 사용자와의 대화환경에서, 등록된 여러 Function을 동적으로 호출할 수 있는 “지능형 어시스턴트\\\\\" 생성 💬 김태영 대표 (주)인공지능팩토리 CEO 💌 SNS & Email Email: tykim@aifactory.page Youtube : https://www.youtube.com/@tykimos Facebook : https://www.facebook.com/tykimo Blog : https://tykimos.github.io 📍 테디노트 유튜브 채널 📍 \\\\\"테디노트의 RAG 비법노트\\\\\" 랭체인 강의: https://fastcampus.co.kr/data_online_… 📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314 📝 테디노트(깃헙 블로그) : https://teddylee777.github.io 💻 GitHub 소스코드 저장소: https://github.com/teddylee777 0개의 댓글 댓글 작성 문의 메일 : contact@aifactory.page대전광역시 서구 만년로 68 번길 15-20, 5 층 504호 ⓒ(주)인공지능팩토리.All rights reserved.\", \"score\": 0.8452414, \"raw_content\": null}, {\"title\": \"강의 - 테디노트\", \"url\": \"https://teddylee777.github.io/lectures/\", \"content\": \"강의 - 테디노트 강의 강의 ⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌 강의 강의 목록 ❤️ 테디노트 유튜브(YouTube) 본 강의를 수강하신 분들이 평균 2~3주 만에 자격증을 취득하고 있습니다. 인프런 강의 상세내용 보러가기 런어데이 강의 상세내용 보러가기 궁금한 사항이 있으면 언제든 질문 주세요. 인프런 강의 상세내용 보러가기 런어데이 강의 상세내용 보러가기 유데미 강의 상세내용 보러가기 궁금한 사항이 있으면 언제든 질문 주세요. 인프런 강의 상세내용 보러가기 런어데이 강의 상세내용 보러가기 차별화된 깃헙 블로그(GitHub blog) 만들어 보고 싶으신 분들께 추천 드립니다🤩 인프런 강의 상세내용 보러가기 스트림릿(streamlit)을 활용하여 파이썬 웹앱 대시보드를 구현해보고 싶으신 분들께 추천 드립니다🤩 인프런 강의 상세내용 보러가기 ❤️ 테디노트 유튜브(YouTube) 그 밖에도 다양한 주제로 강의 영상을 유튜브(YouTube) 채널에 업로드 하고 있어요 깃헙(GitHub)에 혼자서 데이터 분석, 머신러닝, 딥러닝을 스터디 할 수 있도록 주제별로 정리해 놓았어요✌️\", \"score\": 0.76490957, \"raw_content\": \"강의 - 테디노트\\\\n\\\\nSkip to primary navigation\\\\nSkip to content\\\\nSkip to footer\\\\n\\\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\\\n\\\\n검색\\\\n카테고리\\\\n태그\\\\n연도\\\\n강의\\\\n어바웃미\\\\n\\\\n토글 메뉴\\\\n\\\\nHome \\\\n/3.  강의\\\\n\\\\n🔥알림🔥\\\\n① 테디노트 유튜브 - 구경하러 가기!\\\\n② LangChain 한국어 튜토리얼 바로가기 👀\\\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\\\n강의\\\\n강의 목록\\\\n\\\\n🔥 Google 공인! 텐서플로 개발자 자격증 취득\\\\n💻 한 방으로 끝내는 판다스(Pandas) 데이터 분석 - 전자책 포함\\\\n🌱 한 권으로 끝내는 파이썬(Python) 코딩 입문 - 전자책 포함\\\\n🌱 깃헙 블로그(Github blog)로 차별화 된 나만의 홈페이지 만들기!\\\\n🌱 스트림릿(Streamlit)을 활용한 파이썬 웹앱 제작하기\\\\n❤️ 테디노트 유튜브(YouTube)\\\\n✏️ 머신러닝 스터디 혼자 해보기\\\\n\\\\n아래에 나열된 강의는 모두 제가 직접 촬영 및 진행한 내 새끼같은 강의들입니다.\\\\n강의에 대한 후기를 먼저 보시면 아시겠지만, 감사하게도 많은 분들이 수강하고 좋은 평가를 남겨 주셨습니다. 정말 한분 한분 감사하다는 인사를 꼭 드리고 싶습니다🙏\\\\n강의를 제작하면서 이것 하나만큼은 진심이었습니다.\\\\n\\\\n“내 강의를 수강하신 분들의 돈, 시간을 낭비하는 강의는 절대 만들지도 팔지도 않겠다”\\\\n\\\\n혹여 부족한 점이 있다 하더라도 추가 질의 응답을 통해 소통하고 있습니다.\\\\n데이터와 인공지능에 관심있는 분들이 조금이라도 지름길을 걸으실 수 있도록 양질의 콘텐츠 개발에 최선을 다하겠습니다. 감사합니다😊\\\\n🔥 Google 공인! 텐서플로 개발자 자격증 취득\\\\n\\\\n🙏 아래의 내용을 참고해 주세요 🙏\\\\n\\\\n구글에서 공인하는 텐서플로(tensorflow) 자격증 취득을 목표로 해요🤩\\\\n텐서플로(tensorflow)나 딥러닝 프레임워크에 대한 이해가 전혀 없으셔도 관계 없어요😊\\\\n본 강의로 딥러닝에 입문하시기에 좋아요. 입문자의 눈높이로 진행해요🥰\\\\n궁금한 사항이 있으면 24/7 슬랙 채팅방에서 질의 응답이 가능해요👍\\\\n본 강의를 수강하신 분들이 평균 2~3주 만에 자격증을 취득하고 있습니다. 몰입도가 굉장해요🔥\\\\n\\\\n📌 VOD 강의 링크\\\\n\\\\n인프런 강의 상세내용 보러가기\\\\n런어데이 강의 상세내용 보러가기\\\\n\\\\n💻 한 방으로 끝내는 판다스(Pandas) 데이터 분석 - 전자책 포함\\\\n\\\\n🙏 아래의 내용을 참고해 주세요 🙏\\\\n\\\\n판다스 pandas 의 기초 문법부터 고급기능, 그리고 데이터 시각화 matplotlib, seaborn 까지 다룹니다🤩\\\\n데이터 분석은 실습이 중요합니다. 정말 많은 연습문제와 실전예제를 준비했어요😊\\\\n빅데이터 분석기사 실기 준비하시는 분들께 적극 추천 드립니다🥰\\\\n궁금한 사항이 있으면 언제든 질문 주세요. 직접 답변 드립니다👍\\\\n\\\\n📌 VOD 강의 링크\\\\n\\\\n인프런 강의 상세내용 보러가기\\\\n런어데이 강의 상세내용 보러가기\\\\n유데미 강의 상세내용 보러가기\\\\n\\\\n🌱 한 권으로 끝내는 파이썬(Python) 코딩 입문 - 전자책 포함\\\\n\\\\n🙏 아래의 내용을 참고해 주세요 🙏\\\\n\\\\n무료강의 입니다. 파이썬 python 코딩 입문자 분들께 추천 드려요🤩\\\\n코딩이 처음이신 분들! 망설이지 말고 도전하세요😊\\\\n각 단원별 다양한 실습예제가 준비되어 있어요🥰\\\\n궁금한 사항이 있으면 언제든 질문 주세요. 직접 답변 드립니다👍\\\\n\\\\n📌 VOD 강의 링크\\\\n\\\\n인프런 강의 상세내용 보러가기\\\\n런어데이 강의 상세내용 보러가기\\\\n\\\\n🌱 깃헙 블로그(Github blog)로 차별화 된 나만의 홈페이지 만들기!\\\\n\\\\n🙏 아래의 내용을 참고해 주세요 🙏\\\\n\\\\n\\\\n제작부터 커스터마이징까지! 차별화된 깃헙 블로그(GitHub blog) 만들어 보고 싶으신 분들께 추천 드립니다🤩\\\\n\\\\n\\\\n코딩은 거의 없기 때문에 코린이도 문제 없어요😊\\\\n\\\\n\\\\n테디노트와 같은 블로그를 만들어 보고 싶으시다면 지금 바로 도전해 보세요 🥰\\\\n\\\\n\\\\n📌 VOD 강의 링크\\\\n\\\\n인프런 강의 상세내용 보러가기\\\\n\\\\n🌱 스트림릿(Streamlit)을 활용한 파이썬 웹앱 제작하기\\\\n\\\\n🙏 아래의 내용을 참고해 주세요 🙏\\\\n\\\\n\\\\n스트림릿(streamlit)을 활용하여 파이썬 웹앱 대시보드를 구현해보고 싶으신 분들께 추천 드립니다🤩\\\\n\\\\n\\\\n데이터 분석/대시보드 제작 그리고 머신러닝 모델을 배포해서 서비스화 시키는 과정입니다😊\\\\n\\\\n\\\\n파이썬 기본 문법만 알고 계신다면 부담 없이 도전해 보실 수 있어요 🥰\\\\n\\\\n\\\\n📌 VOD 강의 링크\\\\n\\\\n인프런 강의 상세내용 보러가기\\\\n\\\\n❤️ 테디노트 유튜브(YouTube)\\\\n\\\\n그 밖에도 다양한 주제로 강의 영상을 유튜브(YouTube) 채널에 업로드 하고 있어요\\\\n유튜브 채널에서 재생목록을 꼭 클릭해 보세요! 주제별로 강의 영상을 시리즈로 모아 놓았어요😊\\\\n구독, 좋아요👍 그리고 댓글 감사합니다🥰\\\\n📌 지금 당장 유튜브 보러가기\\\\n✏️ 머신러닝 스터디 혼자 해보기\\\\n\\\\n깃헙(GitHub)에 혼자서 데이터 분석, 머신러닝, 딥러닝을 스터디 할 수 있도록 주제별로 정리해 놓았어요✌️\\\\n저도 혼자서 공부를 했었는데, 이해가 쏙쏙 되는 강의와 블로그 주소들을 메모해 두었다가 정리해 본 내용이에요.\\\\n그 밖에 실습파일, 블로그, 논문 등도 잘 정리해 두었으니, 지나가다 쓱 들러보세요😊\\\\n👀 (주의) 내용이 무척 많으니, 다 습득하려 하지 마시고, 모르는 내용만 발췌해서 보세요\\\\n📌 지금 당장 혼공 하러가기\\\\n공유하기\\\\nTwitter Facebook LinkedIn\\\\n댓글남기기\\\\n\\\\n팔로우:\\\\nYouTube\\\\nGitHub\\\\nInstagram\\\\n피드\\\\n\\\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"테디노트 TeddyNote - YouTube\", \"url\": \"https://www.youtube.com/channel/UCt2wAAXgm87ACiQnDHQEW6Q\", \"content\": \"데이터 분석, 머신러닝, 딥러닝, LLM 에 대한 내용을 다룹니다. 연구보다는 개발에 관심이 많습니다 🙇\\u200d♂️🔥 \\\\\"테디노트의 RAG 비법노트\\\\\" 랭체인\", \"score\": 0.7166357, \"raw_content\": null}]' name='tavily_web_search' id='ed1b3ba7-69dc-4430-9460-c069e19ad9c2' tool_call_id='52ee7bde-351d-4a8a-a5f6-7bdc8d68b92e'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='테디노트 YouTube 채널에 대한 검색 결과는 다음과 같습니다:\\n\\n*   **테디노트 YouTube 채널:** 데이터 분석, 머신러닝, 딥러닝, LLM에 대한 내용을 다루는 채널입니다. 연구보다는 개발에 관심이 많다고 합니다. \"테디노트의 RAG 비법노트\" 랭체인 강의도 제공합니다.\\n*   **강의 정보:** 테디노트 채널에서는 다양한 강의 영상이 제공됩니다. 예를 들어, 서울대 PyTorch 딥러닝 강의, 텐서플로 개발자 자격증 취득 과정, 판다스 데이터 분석, 파이썬 코딩 입문, 깃헙 블로그 만들기, 스트림릿을 활용한 파이썬 웹앱 제작 등의 강의가 있습니다.\\n*   **자료:** 깃헙(GitHub)에 데이터 분석, 머신러닝, 딥러닝 스터디 자료를 주제별로 정리해 놓았습니다.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-46b0c5fc-ec52-4fba-9ceb-89bc887b0edb-0' usage_metadata={'input_tokens': 2829, 'output_tokens': 232, 'total_tokens': 3061, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"테디노트 YouTube 채널에 대해서 검색해 줘\"}\n",
    "\n",
    "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
    "        # display_message_tree(value[\"messages\"][-1])\n",
    "        print(value[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6c5ac",
   "metadata": {},
   "source": [
    "도구 호출 후 구조에 대한 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23623eec",
   "metadata": {},
   "source": [
    "![](./image/tool-message-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff003852",
   "metadata": {},
   "source": [
    "- [이전 실행에 대한 LangSmith 추적](https://smith.langchain.com/public/4f82ddfa-a452-40f3-ab09-4eb088b812a4/r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
